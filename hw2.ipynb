{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports and Function Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python version 3.6\n",
    "!pip install nltk -q\n",
    "!pip install gensim -q\n",
    "!pip install textacy -q\n",
    "!pip install contractions -q \n",
    "!pip install -U symspellpy -q\n",
    "!pip install torch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True) \n",
    "\n",
    "from textacy.preprocessing import remove, normalize, replace\n",
    "\n",
    "import contractions\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Definition of Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GLOBALS \n",
    "\n",
    "F_PATH = 'data.tsv'\n",
    "\n",
    "STAR_H = 'star_rating'\n",
    "REVIEW_H = 'review_body'\n",
    "\n",
    "COLS=[STAR_H, REVIEW_H]\n",
    "\n",
    "VAL_STARS = {1, 2, 3, 4, 5}\n",
    "\n",
    "WV = api.load('word2vec-google-news-300')\n",
    "\n",
    "SPELLER = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "bigram_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
    "\n",
    "SPELLER.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "SPELLER.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset generation and pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(f_path=F_PATH):\n",
    "    df = pd.read_csv(f_path, sep='\\t', usecols=COLS, low_memory=False)\n",
    "    df.dropna(inplace=True)\n",
    "    return df.astype({STAR_H:'int32', REVIEW_H: pd.StringDtype()})\n",
    "\n",
    "def get_sample(df, s_size=20000):\n",
    "    grouped = df.groupby(STAR_H)\n",
    "    rat_dfs = [grouped.get_group(rating).sample(n=s_size) for rating in VAL_STARS]\n",
    "    return pd.concat(rat_dfs) \n",
    "\n",
    "def gen_clean(text):\n",
    "    \"\"\"\n",
    "    gen text cleanup \n",
    "    incl removal: extended ws, html tags, urls\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"html.parser\").text #rm html tags \n",
    "    text = replace.urls(text, '')\n",
    "    text = contractions.fix(text)\n",
    "    text = remove.punctuation(text)\n",
    "    text = replace.numbers(text, '')\n",
    "    text = normalize.whitespace(text).lower()\n",
    "    text = replace.emojis(text, '')\n",
    "    toks = rm_stops(text)\n",
    "    \n",
    "    return toks \n",
    "\n",
    "def rm_stops(text): \n",
    "    \"\"\"\n",
    "    remove stop words from text \n",
    "    \"\"\"\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    sans_stops = [tok for tok in word_tokenize(text) if tok not in stops]\n",
    "    return sans_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Format Word2Vec vectors for networks functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def concat_ten(list_of_vecs) :\n",
    "    # returns concatenation of first ten vectors in a list\n",
    "    \n",
    "    l = len(list_of_vecs)\n",
    "    if l>=2: \n",
    "        m = min(10, l)\n",
    "        c = np.concatenate(list_of_vecs[:m])\n",
    "    else:\n",
    "        c = np.array([])\n",
    "        if l==1: c = np.concatenate([c, list_of_vecs[0]])\n",
    "    \n",
    "    while(l<10):\n",
    "        l+=1\n",
    "        c = np.concatenate([c, np.zeros(300,)])\n",
    "\n",
    "    assert c.shape==(3000,)\n",
    "    return c\n",
    "\n",
    "def get_vecs(tok_list):\n",
    "    # fed a list of tokens and attempts to retreive word2vec vectors for each word\n",
    "    # if a word is not found, attempts to correct misspelled words before attempting\n",
    "    # word2vec vector retreival again \n",
    "    \n",
    "    w2v = []\n",
    "    skipped = 0\n",
    "    new_toks = None\n",
    "    \n",
    "    for w in tok_list:\n",
    "        try: \n",
    "            w2v.append(WV[w])\n",
    "        except KeyError: \n",
    "            skipped = 1\n",
    "            break\n",
    "    \n",
    "    if skipped: \n",
    "        w2v = []\n",
    "        new_toks = spell_check(\" \".join(tok_list))\n",
    "        skipped = 0\n",
    "        for w in new_toks: \n",
    "            if w not in set(stopwords.words(\"english\")):\n",
    "                try: w2v.append(WV[w])\n",
    "                except KeyError: continue\n",
    "\n",
    "    return w2v, new_toks\n",
    "\n",
    "def format_vecs(df, only_20=False): \n",
    "    # adds either a column for the first 20 vectors from a review \n",
    "    # or two columns for the average vector and concatenated first ten\n",
    "    # returns df with above changes \n",
    "    \n",
    "    avg_vecs = []\n",
    "    first_ten = []\n",
    "    first_20 = []\n",
    "    \n",
    "    for _, row in df.iterrows(): \n",
    "        w2v, new_toks = get_vecs(row['cl_toks'])\n",
    "        \n",
    "        if new_toks is not None: \n",
    "            row['cl_toks'] = new_toks\n",
    "                    \n",
    "        if only_20: first_20.append(get_twenty(w2v))\n",
    "        \n",
    "        else: \n",
    "            w2v_arr = np.array(w2v) if w2v else np.zeros((1,300))\n",
    "\n",
    "            avg_vecs.append(np.mean(w2v_arr, axis=0))\n",
    "            first_ten.append(concat_ten(w2v))\n",
    "    \n",
    "    if only_20:\n",
    "\n",
    "        df['first_20'] = first_20\n",
    "        return df\n",
    "\n",
    "    df['avg_vecs'] = avg_vecs\n",
    "    df['first_ten_vecs'] = first_ten\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_twenty(list_of_vecs): \n",
    "    # returns a np.array of the first 20 vectors in a review \n",
    "    # padded if needed\n",
    "    \n",
    "    m = min(20, len(list_of_vecs))\n",
    "\n",
    "    if m>=2: \n",
    "        c = np.array(list_of_vecs[:m])\n",
    "    else:\n",
    "        if m==1: \n",
    "            c = np.array(list_of_vecs)\n",
    "        else: \n",
    "            m+=1\n",
    "            c = np.zeros((1,300))\n",
    "        \n",
    "    while(m<20):\n",
    "        m+=1\n",
    "        c = np.append(c, np.zeros((1,300)), axis=0)\n",
    "\n",
    "    assert c.shape==(20, 300)\n",
    "    return c\n",
    "\n",
    "def spell_check(text): \n",
    "    # attempts to spell check\n",
    "    \n",
    "    sugs = SPELLER.lookup_compound(text, max_edit_distance=2)\n",
    "    term = [sug.term for sug in sugs]\n",
    "    n_str = \"  \".join(term).split()\n",
    "    return [t for t in n_str if t in SPELLER.words.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PyTorch Classes for Dataset generation and Networks\n",
    "\n",
    "- I referred to the kaggle tutorial in the assignment spec for the implementation of the `FNNDataset` and `FNN` classes (https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook)\n",
    "- For the RNN implementation I followed the PyTorch tutorial mentioned in the spec (https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)\n",
    "- For GRU, I implemented code from the following article: https://www.educba.com/pytorch-gru/?source=leftnav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch Classes\n",
    "\n",
    "class FNNDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        review = torch.from_numpy(self.data[index])\n",
    "        label = self.labels[index]-1\n",
    "            \n",
    "        return review.to(torch.float32), label\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, dims=300):\n",
    "        super(FNN, self).__init__()\n",
    "        \n",
    "        hidden_1 = 50\n",
    "        hidden_2 = 10\n",
    "\n",
    "        self.fc1 = nn.Linear(dims, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self, samp, hidden):\n",
    "        combined = torch.cat((samp, hidden))\n",
    "\n",
    "        hidden = self.i2h(combined)\n",
    "\n",
    "        output = self.i2o(combined)\n",
    "\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.hidden_size,)\n",
    "    \n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRU, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size) \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, samp, hidden):\n",
    "        output, hidden = self.gru(samp, hidden)\n",
    "        output = self.fc(self.relu(output[:,-1]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PyTorch Training Functions\n",
    "- I referred to the kaggle tutorial referenced in the assignment spec for the implementation of the training function definitions below. (https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fnn(train_loader, valid_loader, model_out, dims=300, n_epochs=50):\n",
    "    valid_loss_min = np.Inf\n",
    "    \n",
    "    model = FNN(dims)\n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        model.train() \n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "\n",
    "        model.eval()\n",
    "        for data, target in valid_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch+1, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            torch.save(model.state_dict(), model_out)\n",
    "            valid_loss_min = valid_loss\n",
    "    return model\n",
    "\n",
    "def run_rnn(train_loader, valid_loader, model_out, batch_size=1000, n_epochs=4, n_hidden=20, lr=0.005):\n",
    "    \n",
    "    valid_loss_min = np.Inf    \n",
    "\n",
    "    rnn = RNN(300, n_hidden, 5)\n",
    "    optimizer = torch.optim.SGD(rnn.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        rnn.train() \n",
    "        for data, targets in train_loader:\n",
    "            for i in range(data.size()[0]):\n",
    "                \n",
    "                review_tensor = data[i]                \n",
    "                rating = targets[i]\n",
    "                hidden = rnn.init_hidden()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                for j in range(review_tensor.size()[0]):\n",
    "                    output, hidden = rnn(review_tensor[j], hidden)\n",
    "\n",
    "                loss = criterion(output, rating)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()*data.size(0)\n",
    "                \n",
    "        rnn.eval()\n",
    "        for data, target in valid_loader:            \n",
    "            for i in range(data.size()[0]):\n",
    "                \n",
    "                review_tensor = data[i]\n",
    "                rating = targets[i]\n",
    "                hidden = rnn.init_hidden()\n",
    "                \n",
    "                for j in range(review_tensor.size()[0]):\n",
    "                    output, hidden = rnn(review_tensor[j], hidden)\n",
    "\n",
    "                loss = criterion(output, rating)\n",
    "            \n",
    "                valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch+1, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            torch.save(rnn.state_dict(), model_out)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    return rnn\n",
    "\n",
    "def run_gru(train_loader, valid_loader, model_out, batch_size=1000, n_epochs=4, n_hidden=20, lr=0.005):\n",
    "    \n",
    "    valid_loss_min = np.Inf    \n",
    "\n",
    "    gru = GRU(300, n_hidden, 5)\n",
    "    optimizer = torch.optim.SGD(gru.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        gru.train() \n",
    "        for data, targets in train_loader:\n",
    "            for i in range(data.size()[0]):\n",
    "                \n",
    "                review_tensor = data[i]                \n",
    "                rating = targets[i]\n",
    "                hidden = gru.init_hidden()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output, hidden = gru(review_tensor, hidden)\n",
    "\n",
    "                loss = criterion(output, rating)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()*data.size(0)\n",
    "                \n",
    "        gru.eval()\n",
    "        for data, target in valid_loader:            \n",
    "            for i in range(data.size()[0]):\n",
    "                \n",
    "                review_tensor = data[i]\n",
    "                rating = targets[i]\n",
    "                hidden = gru.init_hidden()\n",
    "\n",
    "                output, hidden = gru(review_tensor, hidden)\n",
    "\n",
    "                loss = criterion(output, rating)\n",
    "            \n",
    "                valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        valid_loss = valid_loss/len(valid_loader.dataset)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch+1, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            torch.save(gru.state_dict(), model_out)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    return gru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset loaders and Accuracy functions \n",
    "- I referred to the kaggle tutorial provided in the assignment spec for the dataset loader function (https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_loaders(features, categories, batch_size=100, valid_size=0.2): \n",
    "    \n",
    "    X_train, X_test, train_labels, test_labels = train_test_split(features.tolist(), categories.tolist(), test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_data = FNNDataset(X_train, train_labels)\n",
    "    test_data = FNNDataset(X_test, test_labels)\n",
    "\n",
    "    num_workers = 0\n",
    "\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "    valid_loader = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "def get_fnn_acc(model, test_loader): \n",
    "    corr = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader: \n",
    "            outs = model(data)\n",
    "            _, preds= torch.max(outs, 1)\n",
    "            corr += len([targ for targ, pred in zip(targets, preds) if targ==pred])\n",
    "            total += len(targets)\n",
    "            \n",
    "    return corr / total \n",
    "\n",
    "def get_rnn_acc(rnn, test_loader): \n",
    "    corr = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:             \n",
    "            for i in range(data.size()[0]):\n",
    "                review_tensor = data[i]\n",
    "                rating = targets[i]                \n",
    "                hidden = rnn.init_hidden()\n",
    "                \n",
    "                for j in range(review_tensor.size()[0]):\n",
    "                    output, hidden = rnn(review_tensor[j], hidden)  \n",
    "\n",
    "                _, pred= torch.max(output, 0)\n",
    "                corr += 1 if rating.int()==pred.int() else 0\n",
    "                total += 1\n",
    "                \n",
    "    return corr / total\n",
    "\n",
    "def get_gru_acc(gru, test_loader): \n",
    "    corr = 0 \n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:             \n",
    "            for i in range(data.size()[0]):\n",
    "                review_tensor = data[i]\n",
    "                rating = targets[i]                \n",
    "                hidden = gru.init_hidden()\n",
    "                \n",
    "                output, hidden = gru(review_tensor, hidden)  \n",
    "\n",
    "                _, pred= torch.max(output, 0)\n",
    "                corr += 1 if rating.int()==pred.int() else 0\n",
    "                total += 1\n",
    "                \n",
    "    return corr / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 1: Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data()\n",
    "sampled = get_sample(df)\n",
    "sampled['cl_toks'] = sampled[REVIEW_H].apply(gen_clean)\n",
    "sampled.drop(columns=[REVIEW_H], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 2: Word Embedding\n",
    "\n",
    "### Part A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bracelet - Wrist + Neck = [('necklace', 0.5466936826705933)]\n",
      "Girl + age = [('boy', 0.7243723273277283)]\n",
      "Family - Child = [('friends', 0.3765709400177002)]\n"
     ]
    }
   ],
   "source": [
    "wv_bracelet = WV.most_similar(negative=[\"wrist\"], positive=['bracelet', 'neck'], topn=1)\n",
    "wv_girl = WV.most_similar( positive=['girl', 'age'], topn=1)\n",
    "wv_family = WV.most_similar(negative=['child'], positive=['family'], topn=1)\n",
    "\n",
    "print(f\"Bracelet - Wrist + Neck = {wv_bracelet}\")\n",
    "print(f\"Girl + age = {wv_girl}\")\n",
    "print(f\"Family - Child = {wv_family}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part B\n",
    "\n",
    "**Q:** What do you conclude from comparing vectors generated by yourself and the pretrained model? <br>\n",
    "\n",
    "&emsp; **A:** The google model seems to have a higher degree of accuracy when identifying encoded similarity. This behavior is expected since the google model was trained on data with greater variance. That is, the google model was provided more context on similarities between words and had the ability to tune the vectors to a higher degree of accuracy. \n",
    "    \n",
    "**Q:** Which of the Word2Vec models seems to encode semantic similarities between words better?<br>\n",
    "\n",
    "&emsp; **A:** The imported google model seems to encode semantic similarities better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=sampled['cl_toks'], vector_size=300, window=11, min_count=10, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bracelet - Wrist + Neck = [('necklace', 0.7398298382759094)]\n",
      "Girl + Age = [('teen', 0.9063260555267334)]\n",
      "Family - Child = [('february', 0.6471871137619019)]\n"
     ]
    }
   ],
   "source": [
    "m_bracelet = model.wv.most_similar(negative=[\"wrist\"], positive=['bracelet', 'neck'], topn=1)\n",
    "m_girl = model.wv.most_similar(positive=['girl', 'age'], topn=1)\n",
    "m_family = model.wv.most_similar(negative=['child'], positive=['family'], topn=1)\n",
    "\n",
    "print(f\"Bracelet - Wrist + Neck = {m_bracelet}\")\n",
    "print(f\"Girl + Age = {m_girl}\")\n",
    "print(f\"Family - Child = {m_family}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 3: Simple Models\n",
    "**Note: For full comparison between the features' performance, I opted for the same hyperparameters as the first assignment**\n",
    "<br><br>\n",
    "TF-IDF Accuracies from CA #1: <br>\n",
    "   &emsp; **Perceptron:** 0.39<br>\n",
    "   &emsp; **SVM:** 0.50\n",
    "    \n",
    "**Q:** What do you conclude from comparing performances for the models trained using the two different feature types (TF-IDF and your trained Word2Vec features)? <br>\n",
    "\n",
    "&emsp; **A:** The TF-IDF had higher accuracy ratings for both simple models. Intuitively, this makes sense because of TF-IDF's ability to represent individual term importance. This is likely advantageous when distinguishing the difference between generally positive and generally negative reviews. For example, generally positive reviews will include terms with positive connotations like 'good', 'nice', 'beatutiful', etc. While negative reviews will include terms that have negative connotations like 'bad', 'broken', 'poor', etc. <br>\n",
    "\n",
    "The version of Word2Vec utilized in the models below could only account for the average of vectors per review. Thus, diluting sematic simlarities between reviews and making the classification more difficult. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = format_vecs(sampled)\n",
    "\n",
    "X_train, X_test, train_labels, test_labels = train_test_split(s.avg_vecs.tolist(), s[STAR_H].tolist(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3567\n"
     ]
    }
   ],
   "source": [
    "p = Perceptron(random_state=42, class_weight='balanced', max_iter=20, n_iter_no_change=3)\n",
    "p.fit(X_train, train_labels)\n",
    "p_pred = p.predict(X_test)\n",
    "\n",
    "print(accuracy_score(test_labels, p_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46695\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(penalty='l1', dual=False, random_state=42, max_iter=300)\n",
    "svm.fit(X_train, train_labels)\n",
    "s_pred = svm.predict(X_test)\n",
    "\n",
    "print(accuracy_score(test_labels, s_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 4: Feedforward Neural Networks\n",
    "\n",
    "### Part A: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.289831 \tValidation Loss: 0.321946\n",
      "Epoch: 2 \tTraining Loss: 1.287078 \tValidation Loss: 0.321687\n",
      "Epoch: 3 \tTraining Loss: 1.286229 \tValidation Loss: 0.321438\n",
      "Epoch: 4 \tTraining Loss: 1.284878 \tValidation Loss: 0.321009\n",
      "Epoch: 5 \tTraining Loss: 1.282790 \tValidation Loss: 0.320302\n",
      "Epoch: 6 \tTraining Loss: 1.279050 \tValidation Loss: 0.319021\n",
      "Epoch: 7 \tTraining Loss: 1.271714 \tValidation Loss: 0.316366\n",
      "Epoch: 8 \tTraining Loss: 1.256041 \tValidation Loss: 0.310587\n",
      "Epoch: 9 \tTraining Loss: 1.222833 \tValidation Loss: 0.299115\n",
      "Epoch: 10 \tTraining Loss: 1.169470 \tValidation Loss: 0.284829\n",
      "Epoch: 11 \tTraining Loss: 1.120206 \tValidation Loss: 0.274533\n",
      "Epoch: 12 \tTraining Loss: 1.088898 \tValidation Loss: 0.268469\n",
      "Epoch: 13 \tTraining Loss: 1.069969 \tValidation Loss: 0.265134\n",
      "Epoch: 14 \tTraining Loss: 1.057697 \tValidation Loss: 0.262311\n",
      "Epoch: 15 \tTraining Loss: 1.049132 \tValidation Loss: 0.260301\n",
      "Epoch: 16 \tTraining Loss: 1.042693 \tValidation Loss: 0.258892\n",
      "Epoch: 17 \tTraining Loss: 1.037508 \tValidation Loss: 0.257791\n",
      "Epoch: 18 \tTraining Loss: 1.033101 \tValidation Loss: 0.256611\n",
      "Epoch: 19 \tTraining Loss: 1.028670 \tValidation Loss: 0.255626\n",
      "Epoch: 20 \tTraining Loss: 1.024466 \tValidation Loss: 0.254581\n",
      "Epoch: 21 \tTraining Loss: 1.020242 \tValidation Loss: 0.253377\n",
      "Epoch: 22 \tTraining Loss: 1.015621 \tValidation Loss: 0.252358\n",
      "Epoch: 23 \tTraining Loss: 1.010983 \tValidation Loss: 0.251327\n",
      "Epoch: 24 \tTraining Loss: 1.006361 \tValidation Loss: 0.249915\n",
      "Epoch: 25 \tTraining Loss: 1.001914 \tValidation Loss: 0.248782\n",
      "Epoch: 26 \tTraining Loss: 0.997809 \tValidation Loss: 0.247905\n",
      "Epoch: 27 \tTraining Loss: 0.994027 \tValidation Loss: 0.247101\n",
      "Epoch: 28 \tTraining Loss: 0.990567 \tValidation Loss: 0.246089\n",
      "Epoch: 29 \tTraining Loss: 0.987479 \tValidation Loss: 0.245600\n",
      "Epoch: 30 \tTraining Loss: 0.984749 \tValidation Loss: 0.244827\n",
      "Epoch: 31 \tTraining Loss: 0.982233 \tValidation Loss: 0.244364\n",
      "Epoch: 32 \tTraining Loss: 0.979973 \tValidation Loss: 0.243902\n",
      "Epoch: 33 \tTraining Loss: 0.977932 \tValidation Loss: 0.243460\n",
      "Epoch: 34 \tTraining Loss: 0.975936 \tValidation Loss: 0.243046\n",
      "Epoch: 35 \tTraining Loss: 0.974161 \tValidation Loss: 0.242657\n",
      "Epoch: 36 \tTraining Loss: 0.972507 \tValidation Loss: 0.242480\n",
      "Epoch: 37 \tTraining Loss: 0.970823 \tValidation Loss: 0.242117\n",
      "Epoch: 38 \tTraining Loss: 0.969304 \tValidation Loss: 0.241784\n",
      "Epoch: 39 \tTraining Loss: 0.967818 \tValidation Loss: 0.241441\n",
      "Epoch: 40 \tTraining Loss: 0.966544 \tValidation Loss: 0.241260\n",
      "Epoch: 41 \tTraining Loss: 0.965096 \tValidation Loss: 0.240967\n",
      "Epoch: 42 \tTraining Loss: 0.963770 \tValidation Loss: 0.240654\n",
      "Epoch: 43 \tTraining Loss: 0.962558 \tValidation Loss: 0.241007\n",
      "Epoch: 44 \tTraining Loss: 0.961434 \tValidation Loss: 0.240327\n",
      "Epoch: 45 \tTraining Loss: 0.960330 \tValidation Loss: 0.240094\n",
      "Epoch: 46 \tTraining Loss: 0.959091 \tValidation Loss: 0.240323\n",
      "Epoch: 47 \tTraining Loss: 0.957974 \tValidation Loss: 0.240632\n",
      "Epoch: 48 \tTraining Loss: 0.956971 \tValidation Loss: 0.239614\n",
      "Epoch: 49 \tTraining Loss: 0.955921 \tValidation Loss: 0.239613\n",
      "Epoch: 50 \tTraining Loss: 0.955168 \tValidation Loss: 0.239321\n",
      "\n",
      "\n",
      "Accuracy: 0.47265\n"
     ]
    }
   ],
   "source": [
    "model_out = 'fnn1.pt'\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_loaders(s.avg_vecs, s[STAR_H])\n",
    "run_fnn(train_loader, valid_loader, model_out=model_out)\n",
    "\n",
    "# load best model saved from training\n",
    "fnn1 = FNN(dims=300)\n",
    "fnn1.load_state_dict(torch.load(model_out))\n",
    "acc = get_fnn_acc(fnn1, test_loader)\n",
    "\n",
    "print(f\"\\n\\nAccuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part B:\n",
    "\n",
    "**Q:** What do you conclude by comparing accuracy values you obtain with those obtained in the “’Simple Models” section? <br>\n",
    "\n",
    "&emsp; **A:** The model in part A was able to increase accuracy with an added perceptron layer. This is consistent with my expectations since a model with multiple layers can utilize backpropogation to update weights and biases, thus, enhancing the learning capabilities of the model. Part B, as expected, performed worse than the model trained in part A and SVM. I suspect the lack of accurate performance is due to the difference of features the model was trained on. That is, both SVM and model A were trained on the average of word vectors across each review. These features are likely more representative of each review as a whole in comparison to model B since it was trained using only the first ten terms in each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.293552 \tValidation Loss: 0.321969\n",
      "Epoch: 2 \tTraining Loss: 1.286143 \tValidation Loss: 0.321154\n",
      "Epoch: 3 \tTraining Loss: 1.280997 \tValidation Loss: 0.319141\n",
      "Epoch: 4 \tTraining Loss: 1.266904 \tValidation Loss: 0.313557\n",
      "Epoch: 5 \tTraining Loss: 1.228594 \tValidation Loss: 0.299646\n",
      "Epoch: 6 \tTraining Loss: 1.163305 \tValidation Loss: 0.283670\n",
      "Epoch: 7 \tTraining Loss: 1.108798 \tValidation Loss: 0.273373\n",
      "Epoch: 8 \tTraining Loss: 1.073895 \tValidation Loss: 0.267057\n",
      "Epoch: 9 \tTraining Loss: 1.051187 \tValidation Loss: 0.263268\n",
      "Epoch: 10 \tTraining Loss: 1.035969 \tValidation Loss: 0.260855\n",
      "Epoch: 11 \tTraining Loss: 1.024991 \tValidation Loss: 0.259609\n",
      "Epoch: 12 \tTraining Loss: 1.016362 \tValidation Loss: 0.258689\n",
      "Epoch: 13 \tTraining Loss: 1.009476 \tValidation Loss: 0.258398\n",
      "Epoch: 14 \tTraining Loss: 1.003632 \tValidation Loss: 0.257479\n",
      "Epoch: 15 \tTraining Loss: 0.998481 \tValidation Loss: 0.256827\n",
      "Epoch: 16 \tTraining Loss: 0.993861 \tValidation Loss: 0.256957\n",
      "Epoch: 17 \tTraining Loss: 0.989612 \tValidation Loss: 0.256587\n",
      "Epoch: 18 \tTraining Loss: 0.985948 \tValidation Loss: 0.256281\n",
      "Epoch: 19 \tTraining Loss: 0.982135 \tValidation Loss: 0.256467\n",
      "Epoch: 20 \tTraining Loss: 0.978908 \tValidation Loss: 0.256420\n",
      "Epoch: 21 \tTraining Loss: 0.975518 \tValidation Loss: 0.256527\n",
      "Epoch: 22 \tTraining Loss: 0.972725 \tValidation Loss: 0.256265\n",
      "Epoch: 23 \tTraining Loss: 0.969448 \tValidation Loss: 0.256291\n",
      "Epoch: 24 \tTraining Loss: 0.966579 \tValidation Loss: 0.256426\n",
      "Epoch: 25 \tTraining Loss: 0.963458 \tValidation Loss: 0.256488\n",
      "Epoch: 26 \tTraining Loss: 0.960554 \tValidation Loss: 0.256552\n",
      "Epoch: 27 \tTraining Loss: 0.957317 \tValidation Loss: 0.258122\n",
      "Epoch: 28 \tTraining Loss: 0.954529 \tValidation Loss: 0.256715\n",
      "Epoch: 29 \tTraining Loss: 0.950997 \tValidation Loss: 0.256806\n",
      "Epoch: 30 \tTraining Loss: 0.947747 \tValidation Loss: 0.257582\n",
      "Epoch: 31 \tTraining Loss: 0.944337 \tValidation Loss: 0.257218\n",
      "Epoch: 32 \tTraining Loss: 0.940869 \tValidation Loss: 0.257222\n",
      "Epoch: 33 \tTraining Loss: 0.937251 \tValidation Loss: 0.257585\n",
      "Epoch: 34 \tTraining Loss: 0.933257 \tValidation Loss: 0.257878\n",
      "Epoch: 35 \tTraining Loss: 0.929474 \tValidation Loss: 0.258311\n",
      "Epoch: 36 \tTraining Loss: 0.925617 \tValidation Loss: 0.258529\n",
      "Epoch: 37 \tTraining Loss: 0.921346 \tValidation Loss: 0.258751\n",
      "Epoch: 38 \tTraining Loss: 0.917286 \tValidation Loss: 0.258863\n",
      "Epoch: 39 \tTraining Loss: 0.912283 \tValidation Loss: 0.259329\n",
      "Epoch: 40 \tTraining Loss: 0.907787 \tValidation Loss: 0.259878\n",
      "Epoch: 41 \tTraining Loss: 0.902919 \tValidation Loss: 0.260063\n",
      "Epoch: 42 \tTraining Loss: 0.897883 \tValidation Loss: 0.260654\n",
      "Epoch: 43 \tTraining Loss: 0.892583 \tValidation Loss: 0.261700\n",
      "Epoch: 44 \tTraining Loss: 0.886888 \tValidation Loss: 0.261547\n",
      "Epoch: 45 \tTraining Loss: 0.881278 \tValidation Loss: 0.262745\n",
      "Epoch: 46 \tTraining Loss: 0.875221 \tValidation Loss: 0.263229\n",
      "Epoch: 47 \tTraining Loss: 0.868867 \tValidation Loss: 0.264021\n",
      "Epoch: 48 \tTraining Loss: 0.862615 \tValidation Loss: 0.264368\n",
      "Epoch: 49 \tTraining Loss: 0.856232 \tValidation Loss: 0.267167\n",
      "Epoch: 50 \tTraining Loss: 0.849752 \tValidation Loss: 0.265781\n",
      "\n",
      "\n",
      "Accuracy: 0.4384\n"
     ]
    }
   ],
   "source": [
    "model_out = 'fnn2.pt'\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_loaders(s.first_ten_vecs, s[STAR_H])\n",
    "run_fnn(train_loader, valid_loader, model_out=model_out, dims=3000)\n",
    "\n",
    "# load best model saved from training\n",
    "fnn2 = FNN(dims=3000)\n",
    "fnn2.load_state_dict(torch.load(model_out))\n",
    "acc = get_fnn_acc(fnn2, test_loader)\n",
    "\n",
    "print(f\"\\n\\nAccuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 5: \n",
    "### Part A:\n",
    "\n",
    "**Q:** What do you conclude by comparing accuracy values you obtain with those obtained with feedforward neural network models? <br>\n",
    "\n",
    "&emsp; **A:** As we have discussed in class, RNNs perform best with sequential data. Thus, the performance of the RNN, in comparison to the FNN models, is as expected. While FNN's directly associate inputs with outputs, RNNs focus on the prediction task of what comes next. This attribute of the RNN is not particularly useful for the classification of reviews, so, intuitively the FNNs should have a higher accuracy in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = format_vecs(sampled, only_20=True)\n",
    "model_out= 'rnn.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1282.675225 \tValidation Loss: 323.739831\n",
      "Epoch: 2 \tTraining Loss: 1256.728412 \tValidation Loss: 327.203029\n",
      "Epoch: 3 \tTraining Loss: 1253.001726 \tValidation Loss: 327.260734\n",
      "Epoch: 4 \tTraining Loss: 1248.526298 \tValidation Loss: 325.983668\n",
      "\n",
      "\n",
      "Accuracy: 0.2129\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = get_loaders(s.first_20, s[STAR_H], batch_size=1000)\n",
    "run_rnn(train_loader, valid_loader, model_out=model_out)\n",
    "\n",
    "# load best model saved from training\n",
    "rnn = RNN(300, 20, 5)\n",
    "rnn.load_state_dict(torch.load(model_out))\n",
    "acc = get_rnn_acc(rnn, test_loader)\n",
    "\n",
    "print(f\"\\n\\nAccuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B:\n",
    "**Q:** What do you conclude by comparing accuracy values you obtain with those obtained using simple RNN? <br>\n",
    "&emsp; **A:** As mentioned previously, RNNs are not the ideal network for text classification problems. It follows then, that even with a gated unit cell, the accuracies between the two models would be very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: -505280.279537 \tValidation Loss: -260304.574089\n",
      "Epoch: 2 \tTraining Loss: -1576231.698891 \tValidation Loss: -527594.950278\n",
      "Epoch: 3 \tTraining Loss: -2644560.905676 \tValidation Loss: -793889.721201\n",
      "Epoch: 4 \tTraining Loss: -3705604.375861 \tValidation Loss: -1058912.408795\n",
      "\n",
      "\n",
      "Accuracy: 0.2001\n"
     ]
    }
   ],
   "source": [
    "model_out = 'gru.pt'\n",
    "run_gru(train_loader, valid_loader, model_out=model_out)\n",
    "\n",
    "# load best model saved from training\n",
    "gru = GRU(300, 20, 5)\n",
    "gru.load_state_dict(torch.load(model_out))\n",
    "acc = get_gru_acc(gru, test_loader)\n",
    "\n",
    "print(f\"\\n\\nAccuracy: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
